{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"learn-s\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [\n",
    "    ('Google', 'GOOGL', 'USA', 2984, 'USD'), \n",
    "    ('Netflix', 'NFLX', 'USA', 645, 'USD'),\n",
    "    ('Amazon', 'AMZN', 'USA', 3518, 'USD'),\n",
    "    ('Tesla', 'TSLA', 'USA', 1222, 'USD'),\n",
    "    ('Tencent', '0700', 'Hong Kong', 483, 'HKD'),\n",
    "    ('Toyota', '7203', 'Japan', 2006, 'JPY'),\n",
    "    ('Samsung', '005930', 'Korea', 70600, 'KRW'),\n",
    "    ('Kakao', '035720', 'Korea', 125000, 'KRW'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockSchema = [\"name\", \"ticker\", \"country\", \"price\", \"currency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=stocks, schema=stockSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'),\n",
       " ('ticker', 'string'),\n",
       " ('country', 'string'),\n",
       " ('price', 'bigint'),\n",
       " ('currency', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+------+--------+\n",
      "|   name|ticker|  country| price|currency|\n",
      "+-------+------+---------+------+--------+\n",
      "| Google| GOOGL|      USA|  2984|     USD|\n",
      "|Netflix|  NFLX|      USA|   645|     USD|\n",
      "| Amazon|  AMZN|      USA|  3518|     USD|\n",
      "|  Tesla|  TSLA|      USA|  1222|     USD|\n",
      "|Tencent|  0700|Hong Kong|   483|     HKD|\n",
      "| Toyota|  7203|    Japan|  2006|     JPY|\n",
      "|Samsung|005930|    Korea| 70600|     KRW|\n",
      "|  Kakao|035720|    Korea|125000|     KRW|\n",
      "+-------+------+---------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "| Google|\n",
      "|Netflix|\n",
      "| Amazon|\n",
      "|  Tesla|\n",
      "|Tencent|\n",
      "| Toyota|\n",
      "|Samsung|\n",
      "|  Kakao|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name from stocks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name| price|\n",
      "+-------+------+\n",
      "| Google|  2984|\n",
      "|Netflix|   645|\n",
      "| Amazon|  3518|\n",
      "|  Tesla|  1222|\n",
      "|Tencent|   483|\n",
      "| Toyota|  2006|\n",
      "|Samsung| 70600|\n",
      "|  Kakao|125000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name, price from stocks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name| price|\n",
      "+-------+------+\n",
      "|Samsung| 70600|\n",
      "|  Kakao|125000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name, price from stocks where country = 'Korea'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name| price|\n",
      "+-------+------+\n",
      "| Google|  2984|\n",
      "| Amazon|  3518|\n",
      "| Toyota|  2006|\n",
      "|Samsung| 70600|\n",
      "|  Kakao|125000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name, price from stocks where price > 2000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  name|price|\n",
      "+------+-----+\n",
      "|Google| 2984|\n",
      "|Amazon| 3518|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name, price from stocks where price > 2000 and country = 'USA'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|price|\n",
      "+-------+-----+\n",
      "| Google| 2984|\n",
      "|Netflix|  645|\n",
      "| Amazon| 3518|\n",
      "|  Tesla| 1222|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name, price from stocks where country LIKE 'U%'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select country, avg(price) from stocks group by country\").createOrReplaceTempView(\"stocks_avg_fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|  country|avg(price)|\n",
      "+---------+----------+\n",
      "|Hong Kong|     483.0|\n",
      "|      USA|   2092.25|\n",
      "|    Japan|    2006.0|\n",
      "|    Korea|   97800.0|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from stocks_avg_fat\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings = [\n",
    "    ('Google', 27.99, 'USD'), \n",
    "    ('Netflix', 2.56, 'USD'),\n",
    "    ('Amazon', 6.12, 'USD'),\n",
    "    ('Tesla', 1.86, 'USD'),\n",
    "    ('Tencent', 11.01, 'HKD'),\n",
    "    ('Toyota', 224.82, 'JPY'),\n",
    "    ('Samsung', 1780., 'KRW'),\n",
    "    ('Kakao', 705., 'KRW')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsSchema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"eps\", FloatType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsDF = spark.createDataFrame(data=earnings, schema=earningsSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('eps', 'float'), ('currency', 'string')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earningsDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsDF.createOrReplaceTempView(\"earnings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------+\n",
      "|   name|   eps|currency|\n",
      "+-------+------+--------+\n",
      "| Google| 27.99|     USD|\n",
      "|Netflix|  2.56|     USD|\n",
      "| Amazon|  6.12|     USD|\n",
      "|  Tesla|  1.86|     USD|\n",
      "|Tencent| 11.01|     HKD|\n",
      "| Toyota|224.82|     JPY|\n",
      "|Samsung|1780.0|     KRW|\n",
      "|  Kakao| 705.0|     KRW|\n",
      "+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "earningsDF.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+------+--------+-------+------+--------+\n",
      "|   name|ticker|  country| price|currency|   name|   eps|currency|\n",
      "+-------+------+---------+------+--------+-------+------+--------+\n",
      "|  Kakao|035720|    Korea|125000|     KRW|  Kakao| 705.0|     KRW|\n",
      "|Samsung|005930|    Korea| 70600|     KRW|Samsung|1780.0|     KRW|\n",
      "|  Tesla|  TSLA|      USA|  1222|     USD|  Tesla|  1.86|     USD|\n",
      "| Google| GOOGL|      USA|  2984|     USD| Google| 27.99|     USD|\n",
      "|Tencent|  0700|Hong Kong|   483|     HKD|Tencent| 11.01|     HKD|\n",
      "| Toyota|  7203|    Japan|  2006|     JPY| Toyota|224.82|     JPY|\n",
      "|Netflix|  NFLX|      USA|   645|     USD|Netflix|  2.56|     USD|\n",
      "| Amazon|  AMZN|      USA|  3518|     USD| Amazon|  6.12|     USD|\n",
      "+-------+------+---------+------+--------+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from stocks join earnings on stocks.name = earnings.name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   name|               per|\n",
      "+-------+------------------+\n",
      "|  Kakao| 177.3049645390071|\n",
      "|Samsung|39.662921348314605|\n",
      "|  Tesla|  656.989242258975|\n",
      "| Google| 106.6095042658442|\n",
      "|Tencent| 43.86920889728746|\n",
      "| Toyota| 8.922693419839167|\n",
      "|Netflix| 251.9531306315913|\n",
      "| Amazon| 574.8366120563447|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PER: Price / EPS\n",
    "spark.sql(\"select stocks.name, (price / eps) as per \\\n",
    "  FROM stocks JOIN earnings \\\n",
    "  ON stocks.name = earnings.name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- eps: float (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "earningsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(eps)=344.9200008958578)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earningsDF.agg({\"eps\": \"mean\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(eps)=1.8600000143051147)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "earningsDF.agg(F.min(earningsDF.eps)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(eps)=344.9200008958578)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earningsDF.groupBy().avg().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Kakao', avg(eps)=705.0),\n",
       " Row(name='Samsung', avg(eps)=1780.0),\n",
       " Row(name='Tesla', avg(eps)=1.8600000143051147),\n",
       " Row(name='Google', avg(eps)=27.989999771118164),\n",
       " Row(name='Tencent', avg(eps)=11.010000228881836),\n",
       " Row(name='Toyota', avg(eps)=224.82000732421875),\n",
       " Row(name='Netflix', avg(eps)=2.559999942779541),\n",
       " Row(name='Amazon', avg(eps)=6.119999885559082)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earningsDF.groupBy(earningsDF.name).avg().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = [\n",
    "    (\"jaeho\", 39, \"M\"),\n",
    "    (\"inchul\", 38, \"M\"),\n",
    "    (\"joohyun\", 40, \"F\"),\n",
    "    (\"hyungjin\", 38, \"M\"),\n",
    "    (\"sam\", 35, \"F\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(age)=38.0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField, IntegerType\n",
    "friendsSchema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"sex\", StringType(), True)\n",
    "])\n",
    "\n",
    "friendsDF = spark.createDataFrame(data=friends, schema=friendsSchema)\n",
    "friendsDF.groupBy().avg().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='hyungjin', avg(age)=38.0),\n",
       " Row(name='inchul', avg(age)=38.0),\n",
       " Row(name='jaeho', avg(age)=39.0),\n",
       " Row(name='joohyun', avg(age)=40.0),\n",
       " Row(name='sam', avg(age)=35.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(friendsDF.groupBy('name').agg({'age': 'mean'}).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='hyungjin', avg(age)=38.0),\n",
       " Row(name='inchul', avg(age)=38.0),\n",
       " Row(name='jaeho', avg(age)=39.0),\n",
       " Row(name='joohyun', avg(age)=40.0),\n",
       " Row(name='sam', avg(age)=35.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(friendsDF.groupBy(friendsDF.name).avg().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='hyungjin', age=38, count=1),\n",
       " Row(name='inchul', age=38, count=1),\n",
       " Row(name='jaeho', age=39, count=1),\n",
       " Row(name='joohyun', age=40, count=1),\n",
       " Row(name='sam', age=35, count=1)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(friendsDF.groupBy(['name', friendsDF.age]).count().collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
